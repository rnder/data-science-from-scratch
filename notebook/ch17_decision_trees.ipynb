{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "17. decision trees\n",
    "==\n",
    "다양한 의사결정 경로(decision path)와 결과(outcome)를 나타내는 데 나무 구조를 사용\n",
    "* 이해하고 해석하기 쉽고, 예측할 때 사용하는 프로세스가 명확\n",
    "* 숫자형 데이터, 범주형 데이터를 동시에 다룰수 있고, 특정 변수 값이 누락되어도 사용 가능\n",
    "* 학습 데이터에 대해 '최적의' 의사결정나무를 찾는 것은 계산적으로 무척 어려운 문제, 새로운 데이터에 대한 일반화 성능이 좋지 않게 오버피팅되기 쉬움"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "> **Classification tree**\n",
    ">\n",
    "> Regression tree"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **엔트로피(entropy) - '얼마만큼의 정보를 담고 있는가'**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">데이터셋 S\n",
    "\n",
    ">데이터 포인트 $c_1,....,c_n$\n",
    "* 모든 데이터 포인트가 단 하나의 클래스에 속한다면 엔트로피는 낮고,\n",
    "* 모든 데이터 포인트가 모든 클래스에 고르게 분포되어 있다면 엔트로피는 높다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 클래스에 속할 확률을 $p_i$라고 하면\n",
    "$H(S) = -p_1log_2p_1-...-p_nlog_2p_n$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from collections import Counter, defaultdict\n",
    "from functools import partial\n",
    "import math, random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def entropy(class_probabilities):\n",
    "    \"\"\"클래스에 속할 확률을 입력하면 엔트로피를 계산하라\"\"\"\n",
    "    return sum(-p * math.log(p, 2) for p in class_probabilities if p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#각 클래스 레이블의 확률은 별도로 계산\n",
    "#엔트로피를 구할 때는 어떤 레이블에 어떤 확률값이 주어졌는지까지는 알 필요가 없고, \n",
    "#레이블과 무관하게 확률 값들만 알면됨\n",
    "def class_probabilities(labels):\n",
    "    total_count = len(labels)\n",
    "    return [count / total_count\n",
    "            for count in Counter(labels).values()]\n",
    "\n",
    "def data_entropy(labeled_data):\n",
    "    labels = [label for _, label in labeled_data]\n",
    "    probabilities = class_probabilities(labels)\n",
    "    return entropy(probabilities)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **파티션의 엔트로피**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 데이터 $S$를 $q_1,...,q_m$의 비율을 가지는 파티션 $S_1,...,S_m$로 나눈 경우, 다음과 같은 가중합으로 구한다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* $H = q_1H(S_1) + ... + q_mH(S_m)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* 의사결정나무를 사용할 때는 다양한 값을 가질 수 있는 변수들의 경우를 최대한 피하거나, 변수에 속한 값을 적은 수의 버킷으로 나워서 선택하능한 값의 종류를 줄이는 것이 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def partition_entropy(subsets):\n",
    "    \"\"\"subsets는 레이블이 있는 데이터의 list의 list이다.\n",
    "    그에 대한 파티션 엔트로피를 구하라\"\"\"\n",
    "    total_count = sum(len(subset) for subset in subsets)\n",
    "\n",
    "    return sum( data_entropy(subset) * len(subset) / total_count\n",
    "                for subset in subsets )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **의사결정나무 만들기**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* (input, label) 쌍으로 구성된 인터뷰 후보자 데이터 - input:후보자 정보, label:인터뷰 결과\n",
    "* 결정 노드(decision node) : 질문을 주고 답변에 따라 다른 경로로 안내\n",
    "* 잎 노드(leaf node) : 예측값이 무엇인지 알려줌\n",
    "* **ID3** 알고리즘에 기반해서 구축"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = [\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'no'},   False),\n",
    "        ({'level':'Senior','lang':'Java','tweets':'no','phd':'yes'},  False),\n",
    "        ({'level':'Mid','lang':'Python','tweets':'no','phd':'no'},     True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'no'},  True),\n",
    "        ({'level':'Junior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'R','tweets':'yes','phd':'yes'},    False),\n",
    "        ({'level':'Mid','lang':'R','tweets':'yes','phd':'yes'},        True),\n",
    "        ({'level':'Senior','lang':'Python','tweets':'no','phd':'no'}, False),\n",
    "        ({'level':'Senior','lang':'R','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'yes','phd':'no'}, True),\n",
    "        ({'level':'Senior','lang':'Python','tweets':'yes','phd':'yes'},True),\n",
    "        ({'level':'Mid','lang':'Python','tweets':'no','phd':'yes'},    True),\n",
    "        ({'level':'Mid','lang':'Java','tweets':'yes','phd':'no'},      True),\n",
    "        ({'level':'Junior','lang':'Python','tweets':'no','phd':'yes'},False)\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 1. 가장 낮은 엔트로피를 반환하는 파티션을 찾는다.\n",
    "def partition_by(inputs, attribute):\n",
    "    \"\"\"attribute에 따라 inputs의 파티션을 나누자\"\"\"\n",
    "    groups = defaultdict(list)\n",
    "    for input in inputs:\n",
    "        key = input[0][attribute]\n",
    "        groups[key].append(input)\n",
    "    return groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 2. 엔트로피를 계산\n",
    "def partition_entropy_by(inputs,attribute):\n",
    "    \"\"\"주어진 파티션에 대응되는 엔트로피를 계산\"\"\"\n",
    "    partitions = partition_by(inputs, attribute)\n",
    "    return partition_entropy(partitions.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "level 0.6935361388961919\n",
      "lang 0.8601317128547441\n",
      "tweets 0.7884504573082896\n",
      "phd 0.8921589282623617\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 3. 전체 데이터셋에 대해 엔트로피를 최소화하는 파티션을 찾는다.\n",
    "for key in ['level','lang','tweets','phd']:\n",
    "    print(key, partition_entropy_by(inputs, key))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang 0.4\n",
      "tweets 0.0\n",
      "phd 0.9509775004326938\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#직급의 가능한 각 값에 대해 가지를 나눠 서브트리를 만들자.\n",
    "#직급이 Mid인 경우는 예측값이 True\n",
    "#Senior인 경우 True or False\n",
    "senior_inputs = [(input, label)\n",
    "    for input, label in inputs if input[\"level\"] == \"Senior\"]\n",
    "\n",
    "for key in ['lang', 'tweets', 'phd']:\n",
    "    print(key, partition_entropy_by(senior_inputs, key))\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "lang 0.9509775004326938\n",
      "tweets 0.9509775004326938\n",
      "phd 0.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "junior_inputs = [(input, label)\n",
    "    for input, label in inputs if input[\"level\"] == \"Junior\"]\n",
    "\n",
    "for key in ['lang', 'tweets', 'phd']:\n",
    "    print(key, partition_entropy_by(junior_inputs, key))\n",
    "print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~ \n",
    "                  직급(level)?\n",
    "        ↙(senior)     ↓(mid)     ↘(junior)\n",
    "    <tweets?>       [합격!]      <phd?>\n",
    "    ↙yes  ↘no                     ↙yes  ↘no\n",
    " [합격!]  [불합격!]              [불합격!] [합격!]  \n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **종합** - 일반화\n",
    "* True\n",
    "* False\n",
    "* (변수, 서브트리)로 구성된 tuple"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "~~~\n",
    "('level',\n",
    "    {'Junior': ('phd', {'no' : True, 'yes': False}),\n",
    "     'Mid': True,\n",
    "     'Senior': ('tweets', {'no': False, 'yes': True})})\n",
    "~~~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 만약 새로 입력받은 후보자의 level이 Intern인 경우? \n",
    "**None**이라는 **key**값을 하나 추가하고 가장 빈도가 높은 클래스 레이블을 할당.\n",
    "(실제 데이터에 None값으로 존재한다면 그리 좋은 접근법은 아닐듯...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def classify(tree, input):\n",
    "    \"\"\"의사결정나무 tree로 주어진 입력값 input을 분류\"\"\"\n",
    "\n",
    "    # 잎 노드이면 값을 반환\n",
    "    if tree in [True, False]:\n",
    "        return tree\n",
    "\n",
    "    # 그게 아니라면 데이터의 변수로 파티션을 나눔\n",
    "    # key로 변수 값, 값으로 서브트리를 나타내는 dict를 사용하면됨\n",
    "    attribute, subtree_dict = tree\n",
    "\n",
    "    subtree_key = input.get(attribute)  # None if input is missing attribute\n",
    "\n",
    "    if subtree_key not in subtree_dict: # 키에 해당하는 서브트리가 존재하지 않을때\n",
    "        subtree_key = None              # None 서브트리를 사용\n",
    "\n",
    "    subtree = subtree_dict[subtree_key] # 적절한 서브트리를 선택\n",
    "    return classify(subtree, input)     # 입력된 데이터를 분류"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 이제 학습용 데이터로부터 실제 나무를 구축!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def build_tree_id3(inputs, split_candidates=None):\n",
    "\n",
    "    # if this is our first pass,\n",
    "    # all keys of the first input are split candidates\n",
    "    if split_candidates is None:\n",
    "        split_candidates = inputs[0][0].keys()\n",
    "\n",
    "    # count Trues and Falses in the inputs\n",
    "    num_inputs = len(inputs)\n",
    "    num_trues = len([label for item, label in inputs if label])\n",
    "    num_falses = num_inputs - num_trues\n",
    "\n",
    "    if num_trues == 0:                  # if only Falses are left\n",
    "        return False                    # return a \"False\" leaf\n",
    "\n",
    "    if num_falses == 0:                 # if only Trues are left\n",
    "        return True                     # return a \"True\" leaf\n",
    "\n",
    "    if not split_candidates:            # if no split candidates left\n",
    "        return num_trues >= num_falses  # return the majority leaf\n",
    "\n",
    "    # otherwise, split on the best attribute\n",
    "    best_attribute = min(split_candidates,\n",
    "        key=partial(partition_entropy_by, inputs))\n",
    "\n",
    "    partitions = partition_by(inputs, best_attribute)\n",
    "    new_candidates = [a for a in split_candidates\n",
    "                      if a != best_attribute]\n",
    "\n",
    "    # recursively build the subtrees\n",
    "    subtrees = { attribute : build_tree_id3(subset, new_candidates)\n",
    "                 for attribute, subset in partitions.items() }\n",
    "\n",
    "    subtrees[None] = num_trues > num_falses # default case\n",
    "\n",
    "    return (best_attribute, subtrees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building the tree\n",
      "('level', {'Mid': True, 'Senior': ('tweets', {None: False, 'no': False, 'yes': True}), None: True, 'Junior': ('phd', {None: True, 'no': True, 'yes': False})})\n"
     ]
    }
   ],
   "source": [
    "print(\"building the tree\")\n",
    "tree = build_tree_id3(inputs)\n",
    "print(tree)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Junior / Java / tweets / no phd True\n",
      "Junior / Java / tweets / phd False\n"
     ]
    }
   ],
   "source": [
    "print(\"Junior / Java / tweets / no phd\", classify(tree,\n",
    "    { \"level\" : \"Junior\",\n",
    "      \"lang\" : \"Java\",\n",
    "      \"tweets\" : \"yes\",\n",
    "      \"phd\" : \"no\"} ))\n",
    "\n",
    "print(\"Junior / Java / tweets / phd\", classify(tree,\n",
    "    { \"level\" : \"Junior\",\n",
    "             \"lang\" : \"Java\",\n",
    "             \"tweets\" : \"yes\",\n",
    "             \"phd\" : \"yes\"} ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intern True\n",
      "Senior False\n"
     ]
    }
   ],
   "source": [
    "#심지어 관찰된 적 없는 값이 변수에 등장하거나 변수 값 자체가 누락되더라도 분류가 가능\n",
    "print(\"Intern\", classify(tree, { \"level\" : \"Intern\" } ))\n",
    "print(\"Senior\", classify(tree, { \"level\" : \"Senior\" } ))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#심지어 관찰된 적 없는 값이 변수에 등장하거나 변수 값 자체가 누락되더라도 분류가 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **랜덤포레스트**\n",
    "* 오버피팅을 방지할 수 있는 대표적인 방법 중 하나\n",
    "* 여러 개의 의사결정나무를 만들고, 그들의 다수결로 결과를 결정하는 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def forest_classify(trees, input):\n",
    "    votes = [classify(tree, input) for tree in trees]\n",
    "    vote_counts = Counter(votes)\n",
    "    return vote_counts.most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 랜덤하게 나무를 얻을수 있는 방법(앙상블 학습)\n",
    "* bootstrap aggregating, bagging(배깅) : bootstrap_sample(inputs)의 결과물을 각 나무의 입력값으로 넣어 학습.\n",
    "* 파티션을 나누는 변수에 랜덤성을 부여 : 남아있는 모든 변수중 일부만 선택하고 그중 최적의 변수를 선택."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
